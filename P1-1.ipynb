{"cells":[{"cell_type":"markdown","metadata":{"id":"Rp0VSc2dbZw2"},"source":["<center><div style=\"direction:rtl;font-family:B Lotus, B Nazanin, Tahoma\">به نام خدا</div></center>\n","\n","<h1><center><div style=\"direction:rtl;font-family:B Lotus, B Nazanin, Tahoma\">تمرین عملی 1: طبقه بندی با شبکه های تمام متصل روی مجموعه داده IRIS</div></center></h1>"]},{"cell_type":"markdown","metadata":{"id":"1wTQ1noWbZw9"},"source":["## <div style=\"direction:rtl;text-align:right;font-family:B Lotus, B Nazanin, Tahoma\">صورت مساله</div>\n","\n","\n","<div style=\"direction:rtl;text-align:right;font-family:Tahoma\">\n","در اولین جلسه کارگاه طبقه بندی با شبکه های تمام متصل را دیدیم.\n","<br>\n","توصیه می‌شود حتما نوت بوک‌های زیر را قبل از این تمرین مرور کنید:\n","</div>\n","\n","[04_a Gentle Introduction to Keras - Simple neural network(mlp).ipynb](https://nbviewer.jupyter.org/github/alireza-akhavan/SRU-deeplearning-workshop/blob/master/04_a%20Gentle%20Introduction%20to%20Keras%20-%20Simple%20neural%20network%28mlp%29.ipynb)\n","\n","[05_Dropout.ipynb](https://nbviewer.jupyter.org/github/alireza-akhavan/SRU-deeplearning-workshop/blob/master/05_Dropout.ipynb)\n","\n","<div style=\"direction:rtl;text-align:right;font-family:Tahoma\">\n","در این جلسه با داده های تصویری آشنا شدیم. اما در این تمرین برای اینکه بدانیم کاربرد این مباحث در مسائل غیر تصویری نیز هست  از مجموعه داده ی ساختار یافتهiris  شامل 4 ویژگی برای طول و عرض کاسبرگ و گلبرگ استفاده خواهیم کرد که بتوانیم بر اساس این ویژگی ها نوع گل را از 3 کلاس متفاوت تشخیص دهیم.\n","</div>"]},{"cell_type":"markdown","metadata":{"id":"2KQR7ZRTbZw_"},"source":["## <div style=\"direction:rtl;text-align:right;font-family:B Lotus, B Nazanin, Tahoma\">لود کتابخانه های مورد نیاز </div>\n","<div style=\"direction:rtl;text-align:right;font-family:Tahoma\">\n","کتابخانه های مورد نیاز این تمرین لود شده اند\n","<br>\n","در صورت نیاز میتوانید کتابخانه های بیشتری لود کنید:\n","</div>"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"NlYdD1EMbZxA","executionInfo":{"status":"ok","timestamp":1646989245787,"user_tz":-210,"elapsed":3704,"user":{"displayName":"Alireza Farhadi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7CesyRxX98EEFwii4_Bs-xbWmV6gUPJYipEsw=s64","userId":"05490950080420494193"}}},"outputs":[],"source":["import numpy as np\n","from tensorflow import keras\n","from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout\n","from tensorflow.keras.optimizers import Adam"]},{"cell_type":"markdown","metadata":{"id":"_peZ9JgtbZxC"},"source":["<div style=\"direction:rtl;text-align:right;font-family:Tahoma\">\n","در این تمرین میخواهیم از مجموعه داده iris استفاده کنیم.\n","<br>\n","توضیحات این مجموعه داده در سایت آن موجود است:\n","</div>\n","\n","https://archive.ics.uci.edu/ml/datasets/iris\n","\n","\n","<div style=\"direction:rtl;text-align:right;font-family:Tahoma\">\n","ویژگی ها و کلاس های این مجموعه داده به شرح زیر است:\n","</div>\n","\n","Attribute Information:\n","\n","1. sepal length in cm\n","2. sepal width in cm\n","3. petal length in cm\n","4. petal width in cm\n","\n","class:\n","\n","    Iris Setosa\n","    Iris Versicolour\n","    Iris Virginica\n","\n","<div style=\"direction:rtl;text-align:right;font-family:Tahoma\">\n","این دیتاست در کتابخانه sklearn موجود است\n","<br>\n","در قطعه کد زیر ویژگی ها را در x و برچسب یا labelهای متناظر را در y لود شده است.\n","</div>"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"AW3I0lxlbZxD","executionInfo":{"status":"ok","timestamp":1646989251531,"user_tz":-210,"elapsed":554,"user":{"displayName":"Alireza Farhadi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7CesyRxX98EEFwii4_Bs-xbWmV6gUPJYipEsw=s64","userId":"05490950080420494193"}}},"outputs":[],"source":["iris_data = load_iris() # load the iris dataset"]},{"cell_type":"code","source":["x = iris_data.data\n","y = iris_data.target\n","y.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oIQkigOKmmjl","executionInfo":{"status":"ok","timestamp":1646989254104,"user_tz":-210,"elapsed":11,"user":{"displayName":"Alireza Farhadi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7CesyRxX98EEFwii4_Bs-xbWmV6gUPJYipEsw=s64","userId":"05490950080420494193"}},"outputId":"fda63aa0-030c-4576-c5d9-5243e9746e16"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(150,)"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["y=y.reshape(-1, 1) # Convert data to a single column\n","y.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ac6LOOEnmmZt","executionInfo":{"status":"ok","timestamp":1646989256063,"user_tz":-210,"elapsed":8,"user":{"displayName":"Alireza Farhadi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7CesyRxX98EEFwii4_Bs-xbWmV6gUPJYipEsw=s64","userId":"05490950080420494193"}},"outputId":"2643f382-1635-4dcd-ee9e-dc5292a38076"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(150, 1)"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":[""],"metadata":{"id":"aoma5Nqnmx0Q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-rzebFDgbZxE"},"source":["# <div style=\"direction:rtl;text-align:right;font-family:B Lotus, B Nazanin, Tahoma\">سوال 1:</div>\n","<div style=\"direction:rtl;text-align:right;font-family:Tahoma\">\n","برچسب یا label های ما در حال حاضر عددی است.\n","<br>\n","این اعداد 0 تا 2 هستند و به عبارتی 3 حالت مختلف دارند.\n","<br>\n","این برچسب ها را به فرمت one-hot تبدیل کنید و خروجی را مجدد در y بریزید.\n","\n","<br>\n","<b>راهنمایی: </b>\n","از تابع keras.utils.to_categorical استفاده کنید.\n","</div>"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"-MY0fIwybZxF","executionInfo":{"status":"ok","timestamp":1646989267408,"user_tz":-210,"elapsed":516,"user":{"displayName":"Alireza Farhadi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7CesyRxX98EEFwii4_Bs-xbWmV6gUPJYipEsw=s64","userId":"05490950080420494193"}}},"outputs":[],"source":["y =  keras.utils.to_categorical(y)"]},{"cell_type":"code","source":["y.shape"],"metadata":{"id":"SW3u2tNrqmBe","executionInfo":{"status":"ok","timestamp":1646989269955,"user_tz":-210,"elapsed":4,"user":{"displayName":"Alireza Farhadi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7CesyRxX98EEFwii4_Bs-xbWmV6gUPJYipEsw=s64","userId":"05490950080420494193"}},"outputId":"0307b43a-c685-4952-db81-28fa2ef3a79d","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(150, 3)"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"4Ybl3jvwbZxG"},"source":["<div style=\"direction:rtl;text-align:right;font-family:Tahoma\">\n","در زیر داده ها  به داده های test و train تقسیم شده است:\n","</div>"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"QQCRy_lmbZxG","executionInfo":{"status":"ok","timestamp":1646989275418,"user_tz":-210,"elapsed":488,"user":{"displayName":"Alireza Farhadi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7CesyRxX98EEFwii4_Bs-xbWmV6gUPJYipEsw=s64","userId":"05490950080420494193"}}},"outputs":[],"source":["# Split the data for training and testing\n","train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.20)"]},{"cell_type":"markdown","metadata":{"id":"eyxFMTZfbZxH"},"source":["# <div style=\"direction:rtl;text-align:right;font-family:B Lotus, B Nazanin, Tahoma\">سوال 2:</div>\n","<div style=\"direction:rtl;text-align:right;font-family:Tahoma\">\n","یک شبکه با دو hidden-layer در هر لایه 10 نوران و تابع فعالیت relu بسازید. یک لایه Dropout با نرخ 0.5 در لایه آخر ماقبل softmax نیز اضافه کنید.\n","</div>"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"Vun29qTAbZxH","executionInfo":{"status":"ok","timestamp":1646989281025,"user_tz":-210,"elapsed":682,"user":{"displayName":"Alireza Farhadi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7CesyRxX98EEFwii4_Bs-xbWmV6gUPJYipEsw=s64","userId":"05490950080420494193"}}},"outputs":[],"source":["from keras.backend import dropout\n","# Build the model\n","model = Sequential()\n","model.add(Dense(10,activation='relu',input_dim=4))\n","model.add(Dense(10,activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(3,activation='softmax'))"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RRTJozIlbZxI","executionInfo":{"status":"ok","timestamp":1646989284631,"user_tz":-210,"elapsed":537,"user":{"displayName":"Alireza Farhadi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7CesyRxX98EEFwii4_Bs-xbWmV6gUPJYipEsw=s64","userId":"05490950080420494193"}},"outputId":"8fbe7ba3-4112-458f-8bde-c06206bd4811"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense (Dense)               (None, 10)                50        \n","                                                                 \n"," dense_1 (Dense)             (None, 10)                110       \n","                                                                 \n"," dropout (Dropout)           (None, 10)                0         \n","                                                                 \n"," dense_2 (Dense)             (None, 3)                 33        \n","                                                                 \n","=================================================================\n","Total params: 193\n","Trainable params: 193\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"markdown","metadata":{"id":"Do-lEpCEbZxI"},"source":["<div style=\"direction:rtl;text-align:right;font-family:Tahoma\">در زیر مدل کامپایل شده است.</div>"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PYkBadfGbZxJ","executionInfo":{"status":"ok","timestamp":1646989292807,"user_tz":-210,"elapsed":523,"user":{"displayName":"Alireza Farhadi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7CesyRxX98EEFwii4_Bs-xbWmV6gUPJYipEsw=s64","userId":"05490950080420494193"}},"outputId":"0f7a5d42-be1e-4c43-9abb-e5bd44d0726b"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(Adam, self).__init__(name, **kwargs)\n"]}],"source":["# Adam optimizer with learning rate of 0.001\n","optimizer = Adam(lr=0.001)\n","model.compile(optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"]},{"cell_type":"markdown","metadata":{"id":"WdCWnF7ebZxJ"},"source":["# <div style=\"direction:rtl;text-align:right;font-family:B Lotus, B Nazanin, Tahoma\">سوال 3:</div>\n","<div style=\"direction:rtl;text-align:right;font-family:Tahoma\">\n","مدل را با  batch_size=5 و تعداد 200 ایپاک آموزش دهید.\n","<br>\n","<b>راهنمایی: </b>\n","از تابع model.fit استفاده کنید.\n","</div>"]},{"cell_type":"code","source":["# Train the model\n","model.fit(train_x,train_y,batch_size=5,epochs=200)"],"metadata":{"id":"6vXQsvgeu8qW","executionInfo":{"status":"ok","timestamp":1646989306703,"user_tz":-210,"elapsed":12262,"user":{"displayName":"Alireza Farhadi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7CesyRxX98EEFwii4_Bs-xbWmV6gUPJYipEsw=s64","userId":"05490950080420494193"}},"outputId":"260f1a9c-b3d4-4b7d-da2e-20e932e0d1f9","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/200\n","24/24 [==============================] - 1s 2ms/step - loss: 1.0551 - accuracy: 0.4917\n","Epoch 2/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.8968 - accuracy: 0.5000\n","Epoch 3/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.8056 - accuracy: 0.4667\n","Epoch 4/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.8115 - accuracy: 0.5417\n","Epoch 5/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.7974 - accuracy: 0.5583\n","Epoch 6/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.8024 - accuracy: 0.5000\n","Epoch 7/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.7810 - accuracy: 0.5000\n","Epoch 8/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.6997 - accuracy: 0.6000\n","Epoch 9/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.6869 - accuracy: 0.6500\n","Epoch 10/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.7047 - accuracy: 0.6250\n","Epoch 11/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.6745 - accuracy: 0.6167\n","Epoch 12/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.7075 - accuracy: 0.5667\n","Epoch 13/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.6711 - accuracy: 0.6417\n","Epoch 14/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.6480 - accuracy: 0.6667\n","Epoch 15/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.6339 - accuracy: 0.6917\n","Epoch 16/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.6337 - accuracy: 0.6917\n","Epoch 17/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.6546 - accuracy: 0.7000\n","Epoch 18/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.5427 - accuracy: 0.7833\n","Epoch 19/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.5763 - accuracy: 0.7333\n","Epoch 20/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.6029 - accuracy: 0.7500\n","Epoch 21/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.5619 - accuracy: 0.7583\n","Epoch 22/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.5861 - accuracy: 0.6833\n","Epoch 23/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.5259 - accuracy: 0.7917\n","Epoch 24/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.5988 - accuracy: 0.7167\n","Epoch 25/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.5911 - accuracy: 0.7583\n","Epoch 26/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.5902 - accuracy: 0.7333\n","Epoch 27/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.5820 - accuracy: 0.7417\n","Epoch 28/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.5187 - accuracy: 0.7833\n","Epoch 29/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.4870 - accuracy: 0.8417\n","Epoch 30/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.5545 - accuracy: 0.7667\n","Epoch 31/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.5215 - accuracy: 0.7667\n","Epoch 32/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.8000\n","Epoch 33/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.8167\n","Epoch 34/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.5363 - accuracy: 0.7833\n","Epoch 35/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.4999 - accuracy: 0.8000\n","Epoch 36/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.4790 - accuracy: 0.8333\n","Epoch 37/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.4972 - accuracy: 0.7917\n","Epoch 38/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.4714 - accuracy: 0.8333\n","Epoch 39/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.5284 - accuracy: 0.7917\n","Epoch 40/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.4871 - accuracy: 0.8167\n","Epoch 41/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.8250\n","Epoch 42/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.5375 - accuracy: 0.7833\n","Epoch 43/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.4082 - accuracy: 0.8833\n","Epoch 44/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.8167\n","Epoch 45/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.4840 - accuracy: 0.7917\n","Epoch 46/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.8333\n","Epoch 47/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.4708 - accuracy: 0.8083\n","Epoch 48/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.8333\n","Epoch 49/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.8333\n","Epoch 50/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.4881 - accuracy: 0.7917\n","Epoch 51/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.7917\n","Epoch 52/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.4683 - accuracy: 0.8000\n","Epoch 53/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.4161 - accuracy: 0.8583\n","Epoch 54/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.5253 - accuracy: 0.7500\n","Epoch 55/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3810 - accuracy: 0.8833\n","Epoch 56/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.4051 - accuracy: 0.8583\n","Epoch 57/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3653 - accuracy: 0.8917\n","Epoch 58/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.4805 - accuracy: 0.8083\n","Epoch 59/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.4024 - accuracy: 0.8583\n","Epoch 60/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.8167\n","Epoch 61/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3887 - accuracy: 0.8667\n","Epoch 62/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3766 - accuracy: 0.8667\n","Epoch 63/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.4049 - accuracy: 0.8333\n","Epoch 64/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3883 - accuracy: 0.8417\n","Epoch 65/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.4074 - accuracy: 0.8667\n","Epoch 66/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3430 - accuracy: 0.8667\n","Epoch 67/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.4083 - accuracy: 0.8000\n","Epoch 68/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.4109 - accuracy: 0.8167\n","Epoch 69/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.4206 - accuracy: 0.8417\n","Epoch 70/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7833\n","Epoch 71/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3726 - accuracy: 0.8833\n","Epoch 72/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3870 - accuracy: 0.8333\n","Epoch 73/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 0.7917\n","Epoch 74/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.4109 - accuracy: 0.8333\n","Epoch 75/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3759 - accuracy: 0.8917\n","Epoch 76/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3877 - accuracy: 0.8500\n","Epoch 77/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.4100 - accuracy: 0.8333\n","Epoch 78/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3538 - accuracy: 0.8667\n","Epoch 79/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3951 - accuracy: 0.8333\n","Epoch 80/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3926 - accuracy: 0.8500\n","Epoch 81/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.8000\n","Epoch 82/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.4090 - accuracy: 0.8250\n","Epoch 83/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3611 - accuracy: 0.8917\n","Epoch 84/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.4102 - accuracy: 0.8333\n","Epoch 85/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.8167\n","Epoch 86/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3669 - accuracy: 0.8333\n","Epoch 87/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3201 - accuracy: 0.8917\n","Epoch 88/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.4545 - accuracy: 0.7833\n","Epoch 89/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3966 - accuracy: 0.8250\n","Epoch 90/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3862 - accuracy: 0.8583\n","Epoch 91/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3543 - accuracy: 0.8667\n","Epoch 92/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.7917\n","Epoch 93/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3763 - accuracy: 0.8167\n","Epoch 94/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3991 - accuracy: 0.8250\n","Epoch 95/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3475 - accuracy: 0.8500\n","Epoch 96/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3890 - accuracy: 0.8333\n","Epoch 97/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3690 - accuracy: 0.8417\n","Epoch 98/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2889 - accuracy: 0.9000\n","Epoch 99/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2580 - accuracy: 0.9000\n","Epoch 100/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3893 - accuracy: 0.8417\n","Epoch 101/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3441 - accuracy: 0.8750\n","Epoch 102/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.8083\n","Epoch 103/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3645 - accuracy: 0.8417\n","Epoch 104/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.4272 - accuracy: 0.8083\n","Epoch 105/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3718 - accuracy: 0.8500\n","Epoch 106/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3582 - accuracy: 0.8750\n","Epoch 107/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3587 - accuracy: 0.8750\n","Epoch 108/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.4001 - accuracy: 0.8167\n","Epoch 109/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.8000\n","Epoch 110/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3744 - accuracy: 0.7917\n","Epoch 111/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3558 - accuracy: 0.8333\n","Epoch 112/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3691 - accuracy: 0.8333\n","Epoch 113/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.4752 - accuracy: 0.7917\n","Epoch 114/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8750\n","Epoch 115/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3039 - accuracy: 0.8667\n","Epoch 116/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3789 - accuracy: 0.8250\n","Epoch 117/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3661 - accuracy: 0.8250\n","Epoch 118/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3597 - accuracy: 0.8500\n","Epoch 119/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.4076 - accuracy: 0.8333\n","Epoch 120/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3727 - accuracy: 0.8583\n","Epoch 121/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3523 - accuracy: 0.8583\n","Epoch 122/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3727 - accuracy: 0.8333\n","Epoch 123/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2564 - accuracy: 0.9000\n","Epoch 124/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3850 - accuracy: 0.8417\n","Epoch 125/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3280 - accuracy: 0.8583\n","Epoch 126/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3483 - accuracy: 0.8417\n","Epoch 127/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3097 - accuracy: 0.9000\n","Epoch 128/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2830 - accuracy: 0.9000\n","Epoch 129/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3198 - accuracy: 0.8667\n","Epoch 130/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3016 - accuracy: 0.8500\n","Epoch 131/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.4039 - accuracy: 0.8167\n","Epoch 132/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3944 - accuracy: 0.8167\n","Epoch 133/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3353 - accuracy: 0.8417\n","Epoch 134/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.4073 - accuracy: 0.8250\n","Epoch 135/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2800 - accuracy: 0.9083\n","Epoch 136/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.4154 - accuracy: 0.8000\n","Epoch 137/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.4131 - accuracy: 0.8000\n","Epoch 138/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3061 - accuracy: 0.8583\n","Epoch 139/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3210 - accuracy: 0.8500\n","Epoch 140/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.8000\n","Epoch 141/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3718 - accuracy: 0.8333\n","Epoch 142/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3534 - accuracy: 0.8500\n","Epoch 143/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3632 - accuracy: 0.8750\n","Epoch 144/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3200 - accuracy: 0.8750\n","Epoch 145/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3691 - accuracy: 0.8667\n","Epoch 146/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3624 - accuracy: 0.8167\n","Epoch 147/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3009 - accuracy: 0.8917\n","Epoch 148/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3511 - accuracy: 0.8250\n","Epoch 149/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3939 - accuracy: 0.8083\n","Epoch 150/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2862 - accuracy: 0.8667\n","Epoch 151/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3749 - accuracy: 0.8250\n","Epoch 152/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3075 - accuracy: 0.8417\n","Epoch 153/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2595 - accuracy: 0.8917\n","Epoch 154/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3086 - accuracy: 0.8583\n","Epoch 155/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3108 - accuracy: 0.8500\n","Epoch 156/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2941 - accuracy: 0.8833\n","Epoch 157/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2761 - accuracy: 0.8583\n","Epoch 158/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3372 - accuracy: 0.8667\n","Epoch 159/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3375 - accuracy: 0.8167\n","Epoch 160/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2558 - accuracy: 0.8833\n","Epoch 161/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2534 - accuracy: 0.9000\n","Epoch 162/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2740 - accuracy: 0.8750\n","Epoch 163/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2716 - accuracy: 0.8583\n","Epoch 164/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2663 - accuracy: 0.9000\n","Epoch 165/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2596 - accuracy: 0.8583\n","Epoch 166/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3249 - accuracy: 0.8417\n","Epoch 167/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2111 - accuracy: 0.9250\n","Epoch 168/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3260 - accuracy: 0.8500\n","Epoch 169/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3255 - accuracy: 0.8500\n","Epoch 170/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2919 - accuracy: 0.8833\n","Epoch 171/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3065 - accuracy: 0.8667\n","Epoch 172/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3355 - accuracy: 0.8583\n","Epoch 173/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3920 - accuracy: 0.7833\n","Epoch 174/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2710 - accuracy: 0.8750\n","Epoch 175/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2820 - accuracy: 0.8917\n","Epoch 176/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2786 - accuracy: 0.8417\n","Epoch 177/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2712 - accuracy: 0.8917\n","Epoch 178/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2874 - accuracy: 0.8667\n","Epoch 179/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3975 - accuracy: 0.8167\n","Epoch 180/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3150 - accuracy: 0.8417\n","Epoch 181/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2979 - accuracy: 0.8583\n","Epoch 182/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3257 - accuracy: 0.8583\n","Epoch 183/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2864 - accuracy: 0.8417\n","Epoch 184/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2464 - accuracy: 0.9000\n","Epoch 185/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2880 - accuracy: 0.8333\n","Epoch 186/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3035 - accuracy: 0.8750\n","Epoch 187/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.2451 - accuracy: 0.9083\n","Epoch 188/200\n","24/24 [==============================] - 0s 3ms/step - loss: 0.2509 - accuracy: 0.9083\n","Epoch 189/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2418 - accuracy: 0.9083\n","Epoch 190/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3046 - accuracy: 0.8417\n","Epoch 191/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2987 - accuracy: 0.8583\n","Epoch 192/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2228 - accuracy: 0.9083\n","Epoch 193/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3358 - accuracy: 0.8750\n","Epoch 194/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2464 - accuracy: 0.9000\n","Epoch 195/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2639 - accuracy: 0.9000\n","Epoch 196/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.3251 - accuracy: 0.8250\n","Epoch 197/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2459 - accuracy: 0.9167\n","Epoch 198/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2918 - accuracy: 0.8667\n","Epoch 199/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2411 - accuracy: 0.9000\n","Epoch 200/200\n","24/24 [==============================] - 0s 2ms/step - loss: 0.2895 - accuracy: 0.8833\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fcb1bd65850>"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"dO0X4mN6bZxK"},"source":["# <div style=\"direction:rtl;text-align:right;font-family:B Lotus, B Nazanin, Tahoma\">سوال 4:</div>\n","<div style=\"direction:rtl;text-align:right;font-family:Tahoma\">\n","مدل را روی داده های test ارزیابی کنید.\n","<br>\n","<b>راهنمایی: </b>\n","از تابع model.evaluate استفاده کنید.\n","</div>"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GS04XLjjbZxK","executionInfo":{"status":"ok","timestamp":1646989315427,"user_tz":-210,"elapsed":599,"user":{"displayName":"Alireza Farhadi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7CesyRxX98EEFwii4_Bs-xbWmV6gUPJYipEsw=s64","userId":"05490950080420494193"}},"outputId":"0cdaa4ef-a2a4-439f-fd63-d9848448d272"},"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step - loss: 0.0761 - accuracy: 0.9667\n","Final test set loss: 0.076148\n","Final test set accuracy: 0.966667\n"]}],"source":["# Test on unseen data\n","results = model.evaluate(test_x, test_y)\n","\n","print('Final test set loss: {:4f}'.format(results[0]))\n","print('Final test set accuracy: {:4f}'.format(results[1]))"]},{"cell_type":"code","source":["results = model.evaluate(test_x, test_y)\n","\n","print('Final test set loss: {:4f}'.format(results[0]))\n","print('Final test set accuracy: {:4f}'.format(results[1]))"],"metadata":{"id":"lb6ZuuciwBx0","executionInfo":{"status":"ok","timestamp":1646914810375,"user_tz":-210,"elapsed":2037,"user":{"displayName":"","photoUrl":"","userId":""}},"outputId":"457be29d-c7f0-493b-fac4-8738ea66bbad","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step - loss: 0.1983 - accuracy: 1.0000\n","Final test set loss: 0.198306\n","Final test set accuracy: 1.000000\n"]}]},{"cell_type":"markdown","metadata":{"id":"b3ndIhagbZxK"},"source":["<div class=\"alert alert-block alert-info\">\n","<div style=\"direction:rtl;text-align:right;font-family:B Lotus, B Nazanin, Tahoma\"> دوره مقدماتی یادگیری عمیق<br>علیرضا اخوان پور<br>پنج شنبه، ۱۸ و ۲۵ بهمن ۱۳۹۷<br>\n","</div>\n","<a href=\"http://class.vision\">Class.Vision</a> - <a href=\"http://AkhavanPour.ir\">AkhavanPour.ir</a> - <a href=\"https://github.com/Alireza-Akhavan/\">GitHub</a>\n","\n","</div>"]}],"metadata":{"kernelspec":{"display_name":"tensorflow","language":"python","name":"tensorflow"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"colab":{"name":"Answer ex1-mlp-iris.ipynb","provenance":[{"file_id":"https://github.com/Alireza-Akhavan/SRU-deeplearning-workshop/blob/master/homework/ex1-mlp-iris.ipynb","timestamp":1646914859064}],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":0}